{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LEYF2I1i7RP",
        "outputId": "a952ccfc-1d73-4ee9-9718-a825a21bae33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading train questions dataset from https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.24M/7.24M [00:00<00:00, 27.7MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished downloading and extracting train questions dataset.\n",
            "Downloading train annotations dataset from https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.7M/21.7M [00:00<00:00, 47.2MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished downloading and extracting train annotations dataset.\n",
            "Downloading train images dataset from http://images.cocodataset.org/zips/train2014.zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13.5G/13.5G [03:20<00:00, 67.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished downloading and extracting train images dataset.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "# %env JOBLIB_TEMP_FOLDER=/tmp\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the URLs for the VQA v2 dataset\n",
        "_URLS = {\n",
        "    \"questions\": {\n",
        "        \"train\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Train_mscoco.zip\",\n",
        "        # \"val\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Val_mscoco.zip\",\n",
        "        # \"test-dev\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Test_mscoco.zip\",\n",
        "        # \"test\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Questions_Test_mscoco.zip\",\n",
        "    },\n",
        "    \"annotations\": {\n",
        "        \"train\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Train_mscoco.zip\",\n",
        "        # \"val\": \"https://s3.amazonaws.com/cvmlp/vqa/mscoco/vqa/v2_Annotations_Val_mscoco.zip\",\n",
        "    },\n",
        "    \"images\": {\n",
        "        \"train\": \"http://images.cocodataset.org/zips/train2014.zip\",\n",
        "        # \"val\": \"http://images.cocodataset.org/zips/val2014.zip\",\n",
        "        # \"test-dev\": \"http://images.cocodataset.org/zips/test2015.zip\",\n",
        "        # \"test\": \"http://images.cocodataset.org/zips/test2015.zip\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# Create a folder to store the dataset files\n",
        "output_dir = \"/content/drive/MyDrive/vqa_v2_data\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Function to download and extract zip files\n",
        "def download_and_extract(url, output_path):\n",
        "    response = requests.get(url, stream=True)\n",
        "    total_size = int(response.headers.get(\"content-length\", 0))\n",
        "    block_size = 1024  # 1 KB\n",
        "    t = tqdm(total=total_size, unit=\"iB\", unit_scale=True)\n",
        "\n",
        "    with open(output_path, \"wb\") as file:\n",
        "        for data in response.iter_content(block_size):\n",
        "            t.update(len(data))\n",
        "            file.write(data)\n",
        "    t.close()\n",
        "\n",
        "    with zipfile.ZipFile(output_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(output_dir)\n",
        "\n",
        "# Download and extract datasets\n",
        "for key, value in _URLS.items():\n",
        "    for name, url in value.items():\n",
        "        zip_file_path = os.path.join(output_dir, f\"{key}_{name}.zip\")\n",
        "        print(f\"Downloading {name} {key} dataset from {url}...\")\n",
        "        download_and_extract(url, zip_file_path)\n",
        "        print(f\"Finished downloading and extracting {name} {key} dataset.\")"
      ]
    }
  ]
}